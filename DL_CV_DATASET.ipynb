{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/upashanadutta23/DLPROJECT/blob/main/DL_CV_DATASET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQGAqHZqsxjX"
      },
      "outputs": [],
      "source": [
        "#Install hugging face datasets\n",
        "!pip install datasets\n",
        "!pip install nibabel\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary Libraries\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset,load_from_disk\n"
      ],
      "metadata": {
        "id": "asRi2G5ntYEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZx_uCZ3tfE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Processing the scanned Brain Data\n",
        "def preprocess_nifti(example):\n",
        "  nii_path = example[\"nii_filepath\"]\n",
        "  #Load the volume data\n",
        "  vol = nib.load(nii_path).get_fdata()\n",
        "  #cropping the sub volume\n",
        "  vol = vol[7:105, 8:132, :108] #(98,124,108)\n",
        "  #shifting intensities so that it is not negative\n",
        "  vol = vol + abs(vol.min())\n",
        "  #normalising it to [0,1]\n",
        "  vol = vol / vol.max()\n",
        "  #converting it to torch tensor(1,1,D,H,W)\n",
        "  t_tensor = torch.from_numpy(vol).unsqueeze(0).unsqueeze(0)\n",
        "  #scale factor based on y dimension(124 -> 96)\n",
        "  scale_factor = 96/124\n",
        "  #downsampling the tensor\n",
        "  downsampled = F.interpolate(t_tensor,scale_factor = (scale_factor,scale_factor,scale_factor),mode = \"trilinear\",align_corners = False)\n",
        "  #scale factor based on y dimension(124 -> 96)\n",
        "  scale_factor = 96/124\n",
        "  #downsampling the tensor\n",
        "  downsampled = F.interpolate(t_tensor,scale_factor = (scale_factor,scale_factor,scale_factor),mode = \"trilinear\",align_corners = False)\n",
        "  #symmetric padding(dim = 96)\n",
        "  _, _, d,h, w = downsampled.shape\n",
        "  pad_d = (96 - d) // 2\n",
        "  pad_h = (96 - h) // 2\n",
        "  pad_w = (96 - w) // 2\n",
        "  padding = (pad_w//2 , pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2, pad_d//2, pad_d - pad_d//2)\n",
        "  final_image = F.pad(downsampled,padding) ##current shape = (1,1,96,96,96)\n",
        "  final_image = final_image.squeeze(0)\n",
        "  #Storing the image as numpy\n",
        "  example[\"img\"] = final_image.numpy()\n",
        "  return example\n"
      ],
      "metadata": {
        "id": "UtdEhT5q0Hdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##LOADING THE DATASET FROM HUGGING FACE\n",
        "ds_train = load_dataset(\"radiata-ai/brain-structure\", split = \"train\", trust_remote_code= True)\n",
        "ds_test = load_dataset(\"radiata-ai/brain-structure\", split = \"test\", trust_remote_code= True)\n",
        "ds_val = load_dataset(\"radiata-ai/brain-structure\", split = \"validation\", trust_remote_code= True)\n"
      ],
      "metadata": {
        "id": "NZ3iTQnY9U3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##THE PREPROCESSING WILL NOW BE APPLIED FOR EACH SPLIT SET\n",
        "ds_train = ds_train.map(preprocess_nifti)\n",
        "ds_test = ds_test.map(preprocess_nifti)\n",
        "ds_val = ds_val.map(preprocess_nifti)\n",
        "#returning it in pytorch tensor format\n",
        "ds_train.set_format(type = 'torch', columns = ['img'])\n",
        "ds_test.set_format(type = 'torch', columns = ['img'])\n",
        "ds_val.set_format(type = 'torch', columns = ['img'])\n"
      ],
      "metadata": {
        "id": "pT1Dfn2M_SGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Save data to disk for uploading\n",
        "ds_train.save_to_disk(\"exported_brain_images/train\")\n",
        "ds_test.save_to_disk(\"exported_brain_images/test\")\n",
        "ds_val.save_to_disk(\"exported_brain_images/val\")\n"
      ],
      "metadata": {
        "id": "SO7gGpiKCzFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the data from disk\n",
        "ds_train = load_from_disk(\"exported_brain_images/train\")\n",
        "ds_test = load_from_disk(\"exported_brain_images/test\")\n",
        "ds_val = load_from_disk(\"exported_brain_images/val\")"
      ],
      "metadata": {
        "id": "jEbxtaKDFNUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}